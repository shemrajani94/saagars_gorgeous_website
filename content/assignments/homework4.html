---
categories:  
- ""    #the front matter should be like the one found in, e.g., blog2.md. It cannot be like the normal Rmd we used
- ""
date: "2023-06-18"
description: Homework 4 # the title that will show up once someone gets to this page
draft: false
image: mlimg.jpg # save picture in \static\img\blogs. Acceptable formats= jpg, jpeg, or png . Your iPhone pics wont work

keywords: ""
slug: hw4 # slug is the shorthand URL address... no spaces plz
title: Building Predictive Classifier In R
---



<div id="the-bechdel-test" class="section level1">
<h1>The Bechdel Test</h1>
<p><a href="https://fivethirtyeight.com/features/the-dollar-and-cents-case-against-hollywoods-exclusion-of-women/" class="uri">https://fivethirtyeight.com/features/the-dollar-and-cents-case-against-hollywoods-exclusion-of-women/</a></p>
<p>The <a href="https://bechdeltest.com">Bechdel test</a> is a way to assess how women are depicted in Hollywood movies. In order for a movie to pass the test:</p>
<ol style="list-style-type: decimal">
<li>It has to have at least two [named] women in it</li>
<li>Who talk to each other</li>
<li>About something besides a man</li>
</ol>
<p>There is a nice article and analysis you can find here <a href="https://fivethirtyeight.com/features/the-dollar-and-cents-case-against-hollywoods-exclusion-of-women/" class="uri">https://fivethirtyeight.com/features/the-dollar-and-cents-case-against-hollywoods-exclusion-of-women/</a>
We have a sample of 1394 movies and we want to fit a model to predict whether a film passes the test or not.</p>
<pre class="r"><code>bechdel &lt;- read_csv(here::here(&quot;content/data&quot;, &quot;bechdel.csv&quot;)) %&gt;% 
  mutate(test = factor(test)) </code></pre>
<pre><code>## Rows: 1394 Columns: 10
## ── Column specification ────────────────────────────────────────────────────────
## Delimiter: &quot;,&quot;
## chr (4): title, test, rated, genre
## dbl (6): year, budget_2013, domgross_2013, intgross_2013, metascore, imdb_ra...
## 
## ℹ Use `spec()` to retrieve the full column specification for this data.
## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
<pre class="r"><code>glimpse(bechdel)</code></pre>
<pre><code>## Rows: 1,394
## Columns: 10
## $ year          &lt;dbl&gt; 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 20…
## $ title         &lt;chr&gt; &quot;12 Years a Slave&quot;, &quot;2 Guns&quot;, &quot;42&quot;, &quot;47 Ronin&quot;, &quot;A Good …
## $ test          &lt;fct&gt; Fail, Fail, Fail, Fail, Fail, Pass, Pass, Fail, Pass, Pa…
## $ budget_2013   &lt;dbl&gt; 2.00, 6.10, 4.00, 22.50, 9.20, 1.20, 1.30, 13.00, 4.00, …
## $ domgross_2013 &lt;dbl&gt; 5.3107035, 7.5612460, 9.5020213, 3.8362475, 6.7349198, 1…
## $ intgross_2013 &lt;dbl&gt; 15.8607035, 13.2493015, 9.5020213, 14.5803842, 30.424919…
## $ rated         &lt;chr&gt; &quot;R&quot;, &quot;R&quot;, &quot;PG-13&quot;, &quot;PG-13&quot;, &quot;R&quot;, &quot;R&quot;, &quot;PG-13&quot;, &quot;PG-13&quot;, …
## $ metascore     &lt;dbl&gt; 97, 55, 62, 29, 28, 55, 48, 33, 90, 58, 52, 78, 83, 53, …
## $ imdb_rating   &lt;dbl&gt; 8.3, 6.8, 7.6, 6.6, 5.4, 7.8, 5.7, 5.0, 7.5, 7.4, 6.2, 7…
## $ genre         &lt;chr&gt; &quot;Biography&quot;, &quot;Action&quot;, &quot;Biography&quot;, &quot;Action&quot;, &quot;Action&quot;, …</code></pre>
<p>How many films fail/pass the test, both as a number and as a %?</p>
<pre class="r"><code>  bechdel %&gt;%
    group_by(test) %&gt;% 
    summarise(test_count = n()) %&gt;% 
    mutate(test_pct = test_count/nrow(bechdel) *100) %&gt;% 
    filter(test == &#39;Pass&#39;)</code></pre>
<pre><code>## # A tibble: 1 × 3
##   test  test_count test_pct
##   &lt;fct&gt;      &lt;int&gt;    &lt;dbl&gt;
## 1 Pass         622     44.6</code></pre>
<div id="movie-scores" class="section level2">
<h2>Movie scores</h2>
<pre class="r"><code>ggplot(data = bechdel, aes(
  x = metascore,
  y = imdb_rating,
  colour = test
)) +
  geom_point(alpha = .3, size = 3) +
  scale_colour_manual(values = c(&quot;tomato&quot;, &quot;olivedrab&quot;)) +
  labs(
    x = &quot;Metacritic score&quot;,
    y = &quot;IMDB rating&quot;,
    colour = &quot;Bechdel test&quot;
  ) +
 theme_light()</code></pre>
<p><img src="/assignments/homework4_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
</div>
</div>
<div id="split-the-data" class="section level1">
<h1>Split the data</h1>
<pre class="r"><code># **Split the data**

set.seed(123)

data_split &lt;- initial_split(bechdel, # updated data
                           prop = 0.8, 
                           strata = test)

bechdel_train &lt;- training(data_split) 
bechdel_test &lt;- testing(data_split)</code></pre>
<p>Check the counts and % (proportions) of the <code>test</code> variable in each set.</p>
<pre class="r"><code>count_bechdel &lt;- function(bechdel_df){
  bechdel_df %&gt;%
    group_by(test) %&gt;% 
    summarise(test_count = n()) %&gt;% 
    mutate(test_pct = test_count/nrow(bechdel_df) *100) %&gt;% 
    filter(test == &#39;Pass&#39;)
}

count_bechdel(bechdel_train)</code></pre>
<pre><code>## # A tibble: 1 × 3
##   test  test_count test_pct
##   &lt;fct&gt;      &lt;int&gt;    &lt;dbl&gt;
## 1 Pass         497     44.6</code></pre>
<pre class="r"><code>count_bechdel(bechdel_test)</code></pre>
<pre><code>## # A tibble: 1 × 3
##   test  test_count test_pct
##   &lt;fct&gt;      &lt;int&gt;    &lt;dbl&gt;
## 1 Pass         125     44.6</code></pre>
<div id="feature-exploration" class="section level2">
<h2>Feature exploration</h2>
</div>
<div id="any-outliers" class="section level2">
<h2>Any outliers?</h2>
<pre class="r"><code>bechdel %&gt;% 
  select(test, budget_2013, domgross_2013, intgross_2013, imdb_rating, metascore) %&gt;% 

    pivot_longer(cols = 2:6,
               names_to = &quot;feature&quot;,
               values_to = &quot;value&quot;) %&gt;% 
  ggplot()+
  aes(x=test, y = value, fill = test)+
  coord_flip()+
  geom_boxplot()+
  facet_wrap(~feature, scales = &quot;free&quot;)+
  theme_bw()+
  theme(legend.position = &quot;none&quot;)+
  labs(x=NULL,y = NULL)</code></pre>
<p><img src="/assignments/homework4_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
</div>
<div id="scatterplot---correlation-matrix" class="section level2">
<h2>Scatterplot - Correlation Matrix</h2>
<p>Write a paragraph discussing the output of the following</p>
<pre class="r"><code>bechdel %&gt;% 
  select(test, budget_2013, domgross_2013, intgross_2013, imdb_rating, metascore)%&gt;% 
  ggpairs(aes(colour=test), alpha=0.2)+
  theme_bw()</code></pre>
<p><img src="/assignments/homework4_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<span style="color: red;">
    <p>Movies that fail the Bechdel test tend to have higher median ratings. The entire box plot is shifted further to the right. This same trend exists with metascore ratings, but the difference in rating is smaller.</p>
    <p>Movies that fail the Bechdel test also tend to have higher budgets than those that pass.</p>
</span>
</div>
<div id="categorical-variables" class="section level2">
<h2>Categorical variables</h2>
<p>Write a paragraph discussing the output of the following</p>
<pre class="r"><code>bechdel %&gt;% 
  group_by(genre, test) %&gt;%
  summarise(n = n()) %&gt;% 
  mutate(prop = n/sum(n))</code></pre>
<pre><code>## `summarise()` has grouped output by &#39;genre&#39;. You can override using the
## `.groups` argument.</code></pre>
<pre><code>## # A tibble: 24 × 4
## # Groups:   genre [14]
##    genre     test      n  prop
##    &lt;chr&gt;     &lt;fct&gt; &lt;int&gt; &lt;dbl&gt;
##  1 Action    Fail    260 0.707
##  2 Action    Pass    108 0.293
##  3 Adventure Fail     52 0.559
##  4 Adventure Pass     41 0.441
##  5 Animation Fail     63 0.677
##  6 Animation Pass     30 0.323
##  7 Biography Fail     36 0.554
##  8 Biography Pass     29 0.446
##  9 Comedy    Fail    138 0.427
## 10 Comedy    Pass    185 0.573
## # ℹ 14 more rows</code></pre>
<pre class="r"><code>bechdel %&gt;% 
  group_by(rated, test) %&gt;%
  summarise(n = n()) %&gt;% 
  mutate(prop = n/sum(n))</code></pre>
<pre><code>## `summarise()` has grouped output by &#39;rated&#39;. You can override using the
## `.groups` argument.</code></pre>
<pre><code>## # A tibble: 10 × 4
## # Groups:   rated [5]
##    rated test      n  prop
##    &lt;chr&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt;
##  1 G     Fail     16 0.615
##  2 G     Pass     10 0.385
##  3 NC-17 Fail      5 0.833
##  4 NC-17 Pass      1 0.167
##  5 PG    Fail    115 0.561
##  6 PG    Pass     90 0.439
##  7 PG-13 Fail    283 0.529
##  8 PG-13 Pass    252 0.471
##  9 R     Fail    353 0.568
## 10 R     Pass    269 0.432</code></pre>
<span style="color: red;">
    <p>Action and animation movies have a lower proportion of movies that pass the test, compared to the whole sample.</p>
    <p>Adventure and Biography movies have a similar proportion pass rate to the whole sample.</p>
    <p>Comedy movies have an above average pass rate for the test, compared to the sample.</p>
</span>
</div>
</div>
<div id="train-first-models.-test-metascore-imdb_rating" class="section level1">
<h1>Train first models. <code>test ~ metascore + imdb_rating</code></h1>
<pre class="r"><code>lr_mod &lt;- logistic_reg() %&gt;% 
  set_engine(engine = &quot;glm&quot;) %&gt;% 
  set_mode(&quot;classification&quot;)

lr_mod</code></pre>
<pre><code>## Logistic Regression Model Specification (classification)
## 
## Computational engine: glm</code></pre>
<pre class="r"><code>tree_mod &lt;- decision_tree() %&gt;% 
  set_engine(engine = &quot;C5.0&quot;) %&gt;% 
  set_mode(&quot;classification&quot;)

tree_mod </code></pre>
<pre><code>## Decision Tree Model Specification (classification)
## 
## Computational engine: C5.0</code></pre>
<pre class="r"><code>lr_fit &lt;- lr_mod %&gt;% # parsnip model
  fit(test ~ metascore + imdb_rating, # a formula
    data = bechdel_train # dataframe
  )

tree_fit &lt;- tree_mod %&gt;% # parsnip model
  fit(test ~ metascore + imdb_rating, # a formula
    data = bechdel_train # dataframe
  )</code></pre>
<div id="logistic-regression" class="section level2">
<h2>Logistic regression</h2>
<pre class="r"><code>lr_fit %&gt;%
  broom::tidy()</code></pre>
<pre><code>## # A tibble: 3 × 5
##   term        estimate std.error statistic  p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)   2.80     0.494        5.68 1.35e- 8
## 2 metascore     0.0207   0.00536      3.86 1.13e- 4
## 3 imdb_rating  -0.625    0.100       -6.24 4.36e-10</code></pre>
<pre class="r"><code>lr_preds &lt;- lr_fit %&gt;%
  augment(new_data = bechdel_train) %&gt;%
  mutate(.pred_match = if_else(test == .pred_Pass, 1, 0))</code></pre>
<div id="confusion-matrix" class="section level3">
<h3>Confusion matrix</h3>
<pre class="r"><code>lr_preds %&gt;% 
  conf_mat(truth = test, estimate = .pred_class) %&gt;% 
  autoplot(type = &quot;heatmap&quot;)</code></pre>
<p><img src="/assignments/homework4_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
</div>
</div>
<div id="decision-tree" class="section level2">
<h2>Decision Tree</h2>
<pre class="r"><code>tree_preds &lt;- tree_fit %&gt;%
  augment(new_data = bechdel) %&gt;%
  mutate(.pred_match = if_else(test == .pred_Pass, 1, 0)) </code></pre>
<pre class="r"><code>tree_preds %&gt;% 
  conf_mat(truth = test, estimate = .pred_class) %&gt;% 
  autoplot(type = &quot;heatmap&quot;)</code></pre>
<p><img src="/assignments/homework4_files/figure-html/unnamed-chunk-14-1.png" width="672" /></p>
</div>
<div id="draw-the-decision-tree" class="section level2">
<h2>Draw the decision tree</h2>
<pre class="r"><code>draw_tree &lt;- 
    rpart::rpart(
        test ~ metascore + imdb_rating,
        data = bechdel_train, # uses data that contains both birth weight and `low`
        control = rpart::rpart.control(maxdepth = 5, cp = 0, minsplit = 10)
    ) %&gt;% 
    partykit::as.party()
plot(draw_tree)</code></pre>
<p><img src="/assignments/homework4_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
</div>
</div>
<div id="cross-validation" class="section level1">
<h1>Cross Validation</h1>
<p>Run the code below. What does it return?</p>
<pre class="r"><code>set.seed(123)
bechdel_folds &lt;- vfold_cv(data = bechdel_train, 
                          v = 3, 
                          strata = test)
bechdel_folds</code></pre>
<pre><code>## #  3-fold cross-validation using stratification 
## # A tibble: 3 × 2
##   splits            id   
##   &lt;list&gt;            &lt;chr&gt;
## 1 &lt;split [742/372]&gt; Fold1
## 2 &lt;split [742/372]&gt; Fold2
## 3 &lt;split [744/370]&gt; Fold3</code></pre>
<span style="color: red;">
    <p>This function returns a dictionary-like data structure with id and split for each cross validation split</p>
</span>
<div id="fit_resamples" class="section level2">
<h2><code>fit_resamples()</code></h2>
<p>Trains and tests a resampled model.</p>
<pre class="r"><code>lr_fit &lt;- lr_mod %&gt;%
  fit_resamples(
    test ~ metascore + imdb_rating,
    resamples = bechdel_folds
  )


tree_fit &lt;- tree_mod %&gt;%
  fit_resamples(
    test ~ metascore + imdb_rating,
    resamples = bechdel_folds
  )</code></pre>
</div>
<div id="collect_metrics" class="section level2">
<h2><code>collect_metrics()</code></h2>
<p>Unnest the metrics column from a tidymodels <code>fit_resamples()</code></p>
<pre class="r"><code>collect_metrics(lr_fit)</code></pre>
<pre><code>## # A tibble: 2 × 6
##   .metric  .estimator  mean     n std_err .config             
##   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
## 1 accuracy binary     0.585     3  0.0143 Preprocessor1_Model1
## 2 roc_auc  binary     0.602     3  0.0190 Preprocessor1_Model1</code></pre>
<pre class="r"><code>collect_metrics(tree_fit)</code></pre>
<pre><code>## # A tibble: 2 × 6
##   .metric  .estimator  mean     n std_err .config             
##   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
## 1 accuracy binary     0.554     3 0.00458 Preprocessor1_Model1
## 2 roc_auc  binary     0.524     3 0.0122  Preprocessor1_Model1</code></pre>
<pre class="r"><code>tree_preds &lt;- tree_mod %&gt;% 
  fit_resamples(
    test ~ metascore + imdb_rating, 
    resamples = bechdel_folds,
    control = control_resamples(save_pred = TRUE) #&lt;&lt;
  )

# What does the data for ROC look like?
tree_preds %&gt;% 
  collect_predictions() %&gt;% 
  roc_curve(truth = test, .pred_Fail)  </code></pre>
<pre><code>## # A tibble: 9 × 3
##   .threshold specificity sensitivity
##        &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;
## 1   -Inf          0           1     
## 2      0.346      0           1     
## 3      0.430      0.0342      0.977 
## 4      0.554      0.137       0.890 
## 5      0.556      0.471       0.556 
## 6      0.569      0.761       0.272 
## 7      0.819      0.952       0.0762
## 8      0.867      0.990       0.0276
## 9    Inf          1           0</code></pre>
<pre class="r"><code># Draw the ROC
tree_preds %&gt;% 
  collect_predictions() %&gt;% 
  roc_curve(truth = test, .pred_Fail) %&gt;% 
  autoplot()</code></pre>
<p><img src="/assignments/homework4_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
</div>
</div>
<div id="build-a-better-training-set-with-recipes" class="section level1">
<h1>Build a better training set with <code>recipes</code></h1>
<div id="preprocessing-options" class="section level2">
<h2>Preprocessing options</h2>
<ul>
<li>Encode categorical predictors</li>
<li>Center and scale variables</li>
<li>Handle class imbalance</li>
<li>Impute missing data</li>
<li>Perform dimensionality reduction</li>
<li>… …</li>
</ul>
</div>
<div id="to-build-a-recipe" class="section level2">
<h2>To build a recipe</h2>
<ol style="list-style-type: decimal">
<li>Start the <code>recipe()</code></li>
<li>Define the variables involved</li>
<li>Describe <strong>prep</strong>rocessing [step-by-step]</li>
</ol>
</div>
<div id="collapse-some-categorical-levels" class="section level2">
<h2>Collapse Some Categorical Levels</h2>
<p>Do we have any <code>genre</code> with few observations? Assign genres that have less than 3% to a new category ‘Other’</p>
<p><img src="/assignments/homework4_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<pre class="r"><code>movie_rec &lt;-
  recipe(test ~ .,
         data = bechdel_train) %&gt;%
  
  # Genres with less than 5% will be in a catewgory &#39;Other&#39;
    step_other(genre, threshold = .03) </code></pre>
</div>
<div id="before-recipe" class="section level2">
<h2>Before recipe</h2>
<pre><code>## # A tibble: 14 × 2
##    genre           n
##    &lt;chr&gt;       &lt;int&gt;
##  1 Action        293
##  2 Comedy        254
##  3 Drama         213
##  4 Adventure      75
##  5 Animation      72
##  6 Crime          68
##  7 Horror         68
##  8 Biography      50
##  9 Mystery         7
## 10 Fantasy         5
## 11 Sci-Fi          3
## 12 Thriller        3
## 13 Documentary     2
## 14 Musical         1</code></pre>
</div>
<div id="after-recipe" class="section level2">
<h2>After recipe</h2>
<pre class="r"><code>movie_rec %&gt;% 
  prep() %&gt;% 
  bake(new_data = bechdel_train) %&gt;% 
  count(genre, sort = TRUE)</code></pre>
<pre><code>## # A tibble: 9 × 2
##   genre         n
##   &lt;fct&gt;     &lt;int&gt;
## 1 Action      293
## 2 Comedy      254
## 3 Drama       213
## 4 Adventure    75
## 5 Animation    72
## 6 Crime        68
## 7 Horror       68
## 8 Biography    50
## 9 other        21</code></pre>
</div>
<div id="step_dummy" class="section level2">
<h2><code>step_dummy()</code></h2>
<p>Converts nominal data into numeric dummy variables</p>
<pre class="r"><code>movie_rec &lt;- recipe(test ~ ., data = bechdel) %&gt;%
  step_other(genre, threshold = .03) %&gt;% 
  step_dummy(all_nominal_predictors()) 

movie_rec </code></pre>
<pre><code>## </code></pre>
<pre><code>## ── Recipe ──────────────────────────────────────────────────────────────────────</code></pre>
<pre><code>## </code></pre>
<pre><code>## ── Inputs</code></pre>
<pre><code>## Number of variables by role</code></pre>
<pre><code>## outcome:   1
## predictor: 9</code></pre>
<pre><code>## </code></pre>
<pre><code>## ── Operations</code></pre>
<pre><code>## • Collapsing factor levels for: genre</code></pre>
<pre><code>## • Dummy variables from: all_nominal_predictors()</code></pre>
</div>
<div id="lets-think-about-the-modelling" class="section level2">
<h2>Let’s think about the modelling</h2>
<p>What if there were no films with <code>rated</code> NC-17 in the training data?</p>
<ul>
<li>Will the model have a coefficient for <code>rated</code> NC-17?</li>
<li>What will happen if the test data includes a film with <code>rated</code> NC-17?</li>
</ul>
</div>
<div id="step_novel" class="section level2">
<h2><code>step_novel()</code></h2>
<p>Adds a catch-all level to a factor for any new values not encountered in model training, which lets R intelligently predict new levels in the test set.</p>
<pre class="r"><code>movie_rec &lt;- recipe(test ~ ., data = bechdel) %&gt;%
  step_other(genre, threshold = .03) %&gt;% 
  step_novel(all_nominal_predictors) %&gt;% # Use *before* `step_dummy()` so new level is dummified
  step_dummy(all_nominal_predictors()) </code></pre>
</div>
<div id="step_zv" class="section level2">
<h2><code>step_zv()</code></h2>
<p>Intelligently handles zero variance variables (variables that contain only a single value)</p>
<pre class="r"><code>movie_rec &lt;- recipe(test ~ ., data = bechdel) %&gt;%
  step_other(genre, threshold = .03) %&gt;% 
  step_novel(all_nominal(), -all_outcomes()) %&gt;% # Use *before* `step_dummy()` so new level is dummified
  step_dummy(all_nominal(), -all_outcomes()) %&gt;% 
  step_zv(all_numeric(), -all_outcomes()) </code></pre>
</div>
<div id="step_normalize" class="section level2">
<h2><code>step_normalize()</code></h2>
<p>Centers then scales numeric variable (mean = 0, sd = 1)</p>
<pre class="r"><code>movie_rec &lt;- recipe(test ~ ., data = bechdel) %&gt;%
  step_other(genre, threshold = .03) %&gt;% 
  step_novel(all_nominal(), -all_outcomes()) %&gt;% # Use *before* `step_dummy()` so new level is dummified
  step_dummy(all_nominal(), -all_outcomes()) %&gt;% 
  step_zv(all_numeric(), -all_outcomes())  %&gt;% 
  step_normalize(all_numeric()) </code></pre>
</div>
<div id="step_corr" class="section level2">
<h2><code>step_corr()</code></h2>
<p>Removes highly correlated variables</p>
<pre class="r"><code>movie_rec &lt;- recipe(test ~ ., data = bechdel) %&gt;%
  step_other(genre, threshold = .03) %&gt;% 
  step_novel(all_nominal(), -all_outcomes()) %&gt;% # Use *before* `step_dummy()` so new level is dummified
  step_dummy(all_nominal(), -all_outcomes()) %&gt;% 
  step_zv(all_numeric(), -all_outcomes())  %&gt;% 
  step_normalize(all_numeric()) 
##%&gt;% 
  ##step_corr(all_predictors(), threshold = 0.75, method = &quot;spearman&quot;) 



movie_rec</code></pre>
<pre><code>## </code></pre>
<pre><code>## ── Recipe ──────────────────────────────────────────────────────────────────────</code></pre>
<pre><code>## </code></pre>
<pre><code>## ── Inputs</code></pre>
<pre><code>## Number of variables by role</code></pre>
<pre><code>## outcome:   1
## predictor: 9</code></pre>
<pre><code>## </code></pre>
<pre><code>## ── Operations</code></pre>
<pre><code>## • Collapsing factor levels for: genre</code></pre>
<pre><code>## • Novel factor level assignment for: all_nominal(), -all_outcomes()</code></pre>
<pre><code>## • Dummy variables from: all_nominal(), -all_outcomes()</code></pre>
<pre><code>## • Zero variance filter on: all_numeric(), -all_outcomes()</code></pre>
<pre><code>## • Centering and scaling for: all_numeric()</code></pre>
</div>
</div>
<div id="define-different-models-to-fit" class="section level1">
<h1>Define different models to fit</h1>
<pre class="r"><code>## Model Building

# 1. Pick a `model type`
# 2. set the `engine`
# 3. Set the `mode`: regression or classification

# Logistic regression
log_spec &lt;-  logistic_reg() %&gt;%  # model type
  set_engine(engine = &quot;glm&quot;) %&gt;%  # model engine
  set_mode(&quot;classification&quot;) # model mode

# Show your model specification
log_spec</code></pre>
<pre><code>## Logistic Regression Model Specification (classification)
## 
## Computational engine: glm</code></pre>
<pre class="r"><code># Decision Tree
tree_spec &lt;- decision_tree() %&gt;%
  set_engine(engine = &quot;C5.0&quot;) %&gt;%
  set_mode(&quot;classification&quot;)

tree_spec</code></pre>
<pre><code>## Decision Tree Model Specification (classification)
## 
## Computational engine: C5.0</code></pre>
<pre class="r"><code># Random Forest
library(ranger)

rf_spec &lt;- 
  rand_forest() %&gt;% 
  set_engine(&quot;ranger&quot;, importance = &quot;impurity&quot;) %&gt;% 
  set_mode(&quot;classification&quot;)


# Boosted tree (XGBoost)
library(xgboost)</code></pre>
<pre><code>## 
## Attaching package: &#39;xgboost&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:dplyr&#39;:
## 
##     slice</code></pre>
<pre class="r"><code>xgb_spec &lt;- 
  boost_tree() %&gt;% 
  set_engine(&quot;xgboost&quot;) %&gt;% 
  set_mode(&quot;classification&quot;) 

# K-nearest neighbour (k-NN)
knn_spec &lt;- 
  nearest_neighbor(neighbors = 4) %&gt;% # we can adjust the number of neighbors 
  set_engine(&quot;kknn&quot;) %&gt;% 
  set_mode(&quot;classification&quot;) </code></pre>
</div>
<div id="bundle-recipe-and-model-with-workflows" class="section level1">
<h1>Bundle recipe and model with <code>workflows</code></h1>
<pre class="r"><code>log_wflow &lt;- # new workflow object
 workflow() %&gt;% # use workflow function
 add_recipe(movie_rec) %&gt;%   # use the new recipe
 add_model(log_spec)   # add your model spec

# show object
log_wflow</code></pre>
<pre><code>## ══ Workflow ════════════════════════════════════════════════════════════════════
## Preprocessor: Recipe
## Model: logistic_reg()
## 
## ── Preprocessor ────────────────────────────────────────────────────────────────
## 5 Recipe Steps
## 
## • step_other()
## • step_novel()
## • step_dummy()
## • step_zv()
## • step_normalize()
## 
## ── Model ───────────────────────────────────────────────────────────────────────
## Logistic Regression Model Specification (classification)
## 
## Computational engine: glm</code></pre>
<pre class="r"><code>## A few more workflows

tree_wflow &lt;-
 workflow() %&gt;%
 add_recipe(movie_rec) %&gt;% 
 add_model(tree_spec) 

rf_wflow &lt;-
 workflow() %&gt;%
 add_recipe(movie_rec) %&gt;% 
 add_model(rf_spec) 

xgb_wflow &lt;-
 workflow() %&gt;%
 add_recipe(movie_rec) %&gt;% 
 add_model(xgb_spec)

knn_wflow &lt;-
 workflow() %&gt;%
 add_recipe(movie_rec) %&gt;% 
 add_model(knn_spec)</code></pre>
<p>HEADS UP</p>
<ol style="list-style-type: decimal">
<li>How many models have you specified?</li>
<li>What’s the difference between a model specification and a workflow?</li>
<li>Do you need to add a formula (e.g., <code>test ~ .</code>) if you have a recipe?</li>
</ol>
</div>
<div id="model-comparison" class="section level1">
<h1>Model Comparison</h1>
<p>You now have all your models. Adapt the code from slides <code>code-from-slides-CA-housing.R</code>, line 400 onwards to assess which model gives you the best classification.</p>
<pre class="r"><code>## Evaluate Models

## Logistic regression results{.smaller}

log_res &lt;- log_wflow %&gt;% 
  fit_resamples(
    resamples = bechdel_folds, 
    metrics = metric_set(
      recall, precision, f_meas, accuracy,
      kap, roc_auc, sens, spec),
    control = control_resamples(save_pred = TRUE)) </code></pre>
<pre><code>## → A | warning: glm.fit: algorithm did not converge</code></pre>
<pre><code>## 
There were issues with some computations   A: x1

                                                 
→ B | warning: prediction from rank-deficient fit; attr(*, &quot;non-estim&quot;) has doubtful cases
## There were issues with some computations   A: x1

There were issues with some computations   A: x1   B: x1

There were issues with some computations   A: x2   B: x1

There were issues with some computations   A: x2   B: x2

There were issues with some computations   A: x3   B: x2

There were issues with some computations   A: x3   B: x3

There were issues with some computations   A: x3   B: x3</code></pre>
<pre class="r"><code># Show average performance over all folds (note that we use log_res):
log_res %&gt;%  collect_metrics(summarize = TRUE)</code></pre>
<pre><code>## # A tibble: 8 × 6
##   .metric   .estimator    mean     n std_err .config             
##   &lt;chr&gt;     &lt;chr&gt;        &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
## 1 accuracy  binary      0.434      3  0.0150 Preprocessor1_Model1
## 2 f_meas    binary      0.346      3  0.0772 Preprocessor1_Model1
## 3 kap       binary     -0.0916     3  0.0140 Preprocessor1_Model1
## 4 precision binary      0.470      3  0.0244 Preprocessor1_Model1
## 5 recall    binary      0.290      3  0.0978 Preprocessor1_Model1
## 6 roc_auc   binary      0.450      3  0.0115 Preprocessor1_Model1
## 7 sens      binary      0.290      3  0.0978 Preprocessor1_Model1
## 8 spec      binary      0.614      3  0.0918 Preprocessor1_Model1</code></pre>
<pre class="r"><code># Show performance for every single fold:
log_res %&gt;%  collect_metrics(summarize = FALSE)</code></pre>
<pre><code>## # A tibble: 24 × 5
##    id    .metric   .estimator .estimate .config             
##    &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               
##  1 Fold1 recall    binary        0.184  Preprocessor1_Model1
##  2 Fold1 precision binary        0.463  Preprocessor1_Model1
##  3 Fold1 f_meas    binary        0.264  Preprocessor1_Model1
##  4 Fold1 accuracy  binary        0.430  Preprocessor1_Model1
##  5 Fold1 kap       binary       -0.0751 Preprocessor1_Model1
##  6 Fold1 sens      binary        0.184  Preprocessor1_Model1
##  7 Fold1 spec      binary        0.735  Preprocessor1_Model1
##  8 Fold1 roc_auc   binary        0.464  Preprocessor1_Model1
##  9 Fold2 recall    binary        0.485  Preprocessor1_Model1
## 10 Fold2 precision binary        0.515  Preprocessor1_Model1
## # ℹ 14 more rows</code></pre>
<pre class="r"><code>## `collect_predictions()` and get confusion matrix{.smaller}

log_pred &lt;- log_res %&gt;% collect_predictions()

log_pred %&gt;%  conf_mat(test, .pred_class) </code></pre>
<pre><code>##           Truth
## Prediction Fail Pass
##       Fail  179  192
##       Pass  438  305</code></pre>
<pre class="r"><code>log_pred %&gt;% 
  conf_mat(test, .pred_class) %&gt;% 
  autoplot(type = &quot;mosaic&quot;) +
  geom_label(aes(
      x = (xmax + xmin) / 2, 
      y = (ymax + ymin) / 2, 
      label = c(&quot;TP&quot;, &quot;FN&quot;, &quot;FP&quot;, &quot;TN&quot;)))</code></pre>
<p><img src="/assignments/homework4_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
<pre class="r"><code>log_pred %&gt;% 
  conf_mat(test, .pred_class) %&gt;% 
  autoplot(type = &quot;heatmap&quot;)</code></pre>
<p><img src="/assignments/homework4_files/figure-html/unnamed-chunk-31-2.png" width="672" /></p>
<pre class="r"><code>## ROC Curve

log_pred %&gt;% 
  group_by(id) %&gt;% # id contains our folds
  roc_curve(test, .pred_Pass) %&gt;% 
  autoplot()</code></pre>
<p><img src="/assignments/homework4_files/figure-html/unnamed-chunk-31-3.png" width="672" /></p>
<pre class="r"><code>## Decision Tree results

tree_res &lt;-
  tree_wflow %&gt;% 
  fit_resamples(
    resamples = bechdel_folds, 
    metrics = metric_set(
      recall, precision, f_meas, 
      accuracy, kap,
      roc_auc, sens, spec),
    control = control_resamples(save_pred = TRUE)
    ) 

tree_res %&gt;%  collect_metrics(summarize = TRUE)</code></pre>
<pre><code>## # A tibble: 8 × 6
##   .metric   .estimator  mean     n std_err .config             
##   &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
## 1 accuracy  binary     0.588     3  0.0147 Preprocessor1_Model1
## 2 f_meas    binary     0.633     3  0.0244 Preprocessor1_Model1
## 3 kap       binary     0.163     3  0.0257 Preprocessor1_Model1
## 4 precision binary     0.623     3  0.0105 Preprocessor1_Model1
## 5 recall    binary     0.647     3  0.0473 Preprocessor1_Model1
## 6 roc_auc   binary     0.589     3  0.0151 Preprocessor1_Model1
## 7 sens      binary     0.647     3  0.0473 Preprocessor1_Model1
## 8 spec      binary     0.515     3  0.0393 Preprocessor1_Model1</code></pre>
<pre class="r"><code>## Random Forest

rf_res &lt;-
  rf_wflow %&gt;% 
  fit_resamples(
    resamples = bechdel_folds, 
    metrics = metric_set(
      recall, precision, f_meas, 
      accuracy, kap,
      roc_auc, sens, spec),
    control = control_resamples(save_pred = TRUE)
    ) 

rf_res %&gt;%  collect_metrics(summarize = TRUE)</code></pre>
<pre><code>## # A tibble: 8 × 6
##   .metric   .estimator  mean     n std_err .config             
##   &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
## 1 accuracy  binary     0.637     3 0.00963 Preprocessor1_Model1
## 2 f_meas    binary     0.703     3 0.00976 Preprocessor1_Model1
## 3 kap       binary     0.247     3 0.0220  Preprocessor1_Model1
## 4 precision binary     0.644     3 0.0112  Preprocessor1_Model1
## 5 recall    binary     0.775     3 0.0285  Preprocessor1_Model1
## 6 roc_auc   binary     0.665     3 0.0150  Preprocessor1_Model1
## 7 sens      binary     0.775     3 0.0285  Preprocessor1_Model1
## 8 spec      binary     0.467     3 0.0407  Preprocessor1_Model1</code></pre>
<pre class="r"><code>## Boosted tree - XGBoost

xgb_res &lt;- 
  xgb_wflow %&gt;% 
  fit_resamples(
    resamples = bechdel_folds, 
    metrics = metric_set(
      recall, precision, f_meas, 
      accuracy, kap,
      roc_auc, sens, spec),
    control = control_resamples(save_pred = TRUE)
    ) 

xgb_res %&gt;% collect_metrics(summarize = TRUE)</code></pre>
<pre><code>## # A tibble: 8 × 6
##   .metric   .estimator  mean     n std_err .config             
##   &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
## 1 accuracy  binary     0.606     3 0.00256 Preprocessor1_Model1
## 2 f_meas    binary     0.657     3 0.0107  Preprocessor1_Model1
## 3 kap       binary     0.195     3 0.00120 Preprocessor1_Model1
## 4 precision binary     0.634     3 0.00426 Preprocessor1_Model1
## 5 recall    binary     0.684     3 0.0288  Preprocessor1_Model1
## 6 roc_auc   binary     0.635     3 0.00299 Preprocessor1_Model1
## 7 sens      binary     0.684     3 0.0288  Preprocessor1_Model1
## 8 spec      binary     0.509     3 0.0303  Preprocessor1_Model1</code></pre>
<pre class="r"><code>## K-nearest neighbour

knn_res &lt;- 
  knn_wflow %&gt;% 
  fit_resamples(
    resamples = bechdel_folds, 
    metrics = metric_set(
      recall, precision, f_meas, 
      accuracy, kap,
      roc_auc, sens, spec),
    control = control_resamples(save_pred = TRUE)
    ) </code></pre>
<pre><code>## → A | warning: While computing binary `precision()`, no predicted events were detected (i.e. `true_positive + false_positive = 0`). 
##                Precision is undefined in this case, and `NA` will be returned.
##                Note that 206 true event(s) actually occured for the problematic event level, &#39;Fail&#39;.
## 
There were issues with some computations   A: x1

There were issues with some computations   A: x1</code></pre>
<pre class="r"><code>knn_res %&gt;% collect_metrics(summarize = TRUE)</code></pre>
<pre><code>## # A tibble: 8 × 6
##   .metric   .estimator  mean     n  std_err .config             
##   &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;chr&gt;               
## 1 accuracy  binary     0.518     3 0.0359   Preprocessor1_Model1
## 2 f_meas    binary     0.713     2 0.000120 Preprocessor1_Model1
## 3 kap       binary     0         3 0        Preprocessor1_Model1
## 4 precision binary     0.554     2 0.000145 Preprocessor1_Model1
## 5 recall    binary     0.667     3 0.333    Preprocessor1_Model1
## 6 roc_auc   binary     0.553     3 0.0284   Preprocessor1_Model1
## 7 sens      binary     0.667     3 0.333    Preprocessor1_Model1
## 8 spec      binary     0.333     3 0.333    Preprocessor1_Model1</code></pre>
<pre class="r"><code>## Model Comparison

log_metrics &lt;- 
  log_res %&gt;% 
  collect_metrics(summarise = TRUE) %&gt;%
  # add the name of the model to every row
  mutate(model = &quot;Logistic Regression&quot;) 

tree_metrics &lt;- 
  tree_res %&gt;% 
  collect_metrics(summarise = TRUE) %&gt;%
  mutate(model = &quot;Decision Tree&quot;)

rf_metrics &lt;- 
  rf_res %&gt;% 
  collect_metrics(summarise = TRUE) %&gt;%
  mutate(model = &quot;Random Forest&quot;)

xgb_metrics &lt;- 
  xgb_res %&gt;% 
  collect_metrics(summarise = TRUE) %&gt;%
  mutate(model = &quot;XGBoost&quot;)

knn_metrics &lt;- 
  knn_res %&gt;% 
  collect_metrics(summarise = TRUE) %&gt;%
  mutate(model = &quot;Knn&quot;)

# create dataframe with all models
model_compare &lt;- bind_rows(log_metrics,
                           tree_metrics,
                           rf_metrics,
                           xgb_metrics,
                           knn_metrics) 

#Pivot wider to create barplot
  model_comp &lt;- model_compare %&gt;% 
  select(model, .metric, mean, std_err) %&gt;% 
  pivot_wider(names_from = .metric, values_from = c(mean, std_err)) 

# show mean are under the curve (ROC-AUC) for every model
model_comp %&gt;% 
  arrange(mean_roc_auc) %&gt;% 
  mutate(model = fct_reorder(model, mean_roc_auc)) %&gt;% # order results
  ggplot(aes(model, mean_roc_auc, fill=model)) +
  geom_col() +
  coord_flip() +
  scale_fill_brewer(palette = &quot;Blues&quot;) +
   geom_text(
     size = 3,
     aes(label = round(mean_roc_auc, 2), 
         y = mean_roc_auc + 0.08),
     vjust = 1
  )+
  theme_light()+
  theme(legend.position = &quot;none&quot;)+
  labs(y = NULL)</code></pre>
<p><img src="/assignments/homework4_files/figure-html/unnamed-chunk-31-4.png" width="672" /></p>
<pre class="r"><code>## `last_fit()` on test set

# - `last_fit()`  fits a model to the whole training data and evaluates it on the test set. 
# - provide the workflow object of the best model as well as the data split object (not the training data). 
 
last_fit_xgb &lt;- last_fit(xgb_wflow, 
                        split = data_split,
                        metrics = metric_set(
                          accuracy, f_meas, kap, precision,
                          recall, roc_auc, sens, spec))

last_fit_xgb %&gt;% collect_metrics(summarize = TRUE)</code></pre>
<pre><code>## # A tibble: 8 × 4
##   .metric   .estimator .estimate .config             
##   &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               
## 1 accuracy  binary         0.568 Preprocessor1_Model1
## 2 f_meas    binary         0.630 Preprocessor1_Model1
## 3 kap       binary         0.114 Preprocessor1_Model1
## 4 precision binary         0.599 Preprocessor1_Model1
## 5 recall    binary         0.665 Preprocessor1_Model1
## 6 sens      binary         0.665 Preprocessor1_Model1
## 7 spec      binary         0.448 Preprocessor1_Model1
## 8 roc_auc   binary         0.610 Preprocessor1_Model1</code></pre>
<pre class="r"><code>#Compare to training
xgb_res %&gt;% collect_metrics(summarize = TRUE)</code></pre>
<pre><code>## # A tibble: 8 × 6
##   .metric   .estimator  mean     n std_err .config             
##   &lt;chr&gt;     &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
## 1 accuracy  binary     0.606     3 0.00256 Preprocessor1_Model1
## 2 f_meas    binary     0.657     3 0.0107  Preprocessor1_Model1
## 3 kap       binary     0.195     3 0.00120 Preprocessor1_Model1
## 4 precision binary     0.634     3 0.00426 Preprocessor1_Model1
## 5 recall    binary     0.684     3 0.0288  Preprocessor1_Model1
## 6 roc_auc   binary     0.635     3 0.00299 Preprocessor1_Model1
## 7 sens      binary     0.684     3 0.0288  Preprocessor1_Model1
## 8 spec      binary     0.509     3 0.0303  Preprocessor1_Model1</code></pre>
<pre class="r"><code>## Variable importance using `{vip}` package

library(vip)

last_fit_xgb %&gt;% 
  pluck(&quot;.workflow&quot;, 1) %&gt;%   
  pull_workflow_fit() %&gt;% 
  vip(num_features = 3) +
  theme_light()</code></pre>
<pre><code>## Warning: `pull_workflow_fit()` was deprecated in workflows 0.2.3.
## ℹ Please use `extract_fit_parsnip()` instead.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was
## generated.</code></pre>
<p><img src="/assignments/homework4_files/figure-html/unnamed-chunk-31-5.png" width="672" /></p>
<pre class="r"><code>## Final Confusion Matrix

last_fit_xgb %&gt;%
  collect_predictions() %&gt;% 
  conf_mat(test, .pred_class) %&gt;% 
  autoplot(type = &quot;heatmap&quot;)</code></pre>
<p><img src="/assignments/homework4_files/figure-html/unnamed-chunk-31-6.png" width="672" /></p>
<pre class="r"><code>## Final ROC curve
last_fit_xgb %&gt;% 
  collect_predictions() %&gt;% 
  roc_curve(test, .pred_Pass) %&gt;% 
  autoplot()</code></pre>
<p><img src="/assignments/homework4_files/figure-html/unnamed-chunk-31-7.png" width="672" /></p>
<span style="color: red;">
    <p>Random forest has highest average area under curve. This means it has highest precision and accuracy</p>
    <p>XGBoost is the next highest AUC, this suggests that the sequential optimizing nature of xgboost is less effective classifier than an ensemble model</p>
</span>
</div>
<div id="details" class="section level1">
<h1>Details</h1>
<ul>
<li>Approximately how much time did you spend on this problem set: 3 hrs</li>
</ul>
</div>
